{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income Predictions - Logistic Regression (Timothy Manolias)\n",
    "\n",
    "### The following program predicts whether an individual makes less than or greater than 50K dollars a year, based on 1994 U.S. census data and a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TEST 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Imports Data and Libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Loads train data\n",
    "train_data = pd.read_csv(\"income_train.csv\")\n",
    "\n",
    "# Loads test data\n",
    "test_data = pd.read_csv(\"income_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Data Preprocessing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Drops unknown values\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "for col in test_data.columns:\n",
    "    train_data.drop(train_data[train_data[col] == '?'].index, inplace = True)\n",
    "    test_data.drop(test_data[test_data[col] == '?'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts income (dependent variable) to dummy variables\n",
    "\n",
    "# train_data\n",
    "train_dummies = pd.get_dummies(train_data_y)\n",
    "if train_data_y['income'][1] not in [0, 1]:\n",
    "    train_data_y = pd.concat((train_data_y, train_dummies['income_>50K']), axis=1)\n",
    "    del train_data_y['income']\n",
    "    train_data_y = train_data_y.rename(columns={\"income_ >50K\": \"income\"})\n",
    "\n",
    "# test_data\n",
    "test_dummies = pd.get_dummies(test_data_y)\n",
    "if test_data_y['income'][1] not in [0, 1]:\n",
    "    test_data_y = pd.concat((test_data_y, test_dummies['income_>50K']), axis=1)\n",
    "    del test_data_y['income']\n",
    "    test_data_y = test_data_y.rename(columns={\"income_ >50K\": \"income\"})        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Data Visualization</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "numeric_features = data.select_dtypes(exclude=[\"object\",\"bool\"])\n",
    "numeric_features = numeric_features.stack().reset_index().rename(columns = {\"level_1\":\"Features\", 0:\"Value\"})\n",
    "\n",
    "g = sns.FacetGrid(data =numeric_features, col=\"Features\",  col_wrap=5, sharex=False, sharey=False)\n",
    "g = g.map(sns.distplot, \"Value\", color ='blue')\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.suptitle(\"Histograms of various features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits data into train and  test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into X and y\n",
    "\n",
    "# train_data\n",
    "train_data_X = train_data.drop(['income'], axis=1)\n",
    "train_data_y = train_data[['income']]\n",
    "\n",
    "# test_data\n",
    "test_data_X = test_data.drop(['income'], axis=1)\n",
    "test_data_y = test_data[['income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Standardization and One-Hot Encoding</font>\n",
    "\n",
    "#### Standardizes continuous features and converts categorical variables into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Gets continuous variables\n",
    "contin_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "contin_train = train_data_X[contin_cols]\n",
    "contin_test = test_data_X[contin_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizes continuous features\n",
    "\n",
    "sc = StandardScaler()\n",
    "for col in contin_cols:\n",
    "    # X_train\n",
    "    temp_train = np.array(contin_train[col]).reshape(-1, 1)\n",
    "    train_data_X[col] = sc.fit_transform(temp_train)\n",
    "    \n",
    "    # X_test\n",
    "    temp_test = np.array(contin_test[col]).reshape(-1, 1)\n",
    "    test_data_X[col] = sc.fit_transform(temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts categorical variables into dummy variables\n",
    "\n",
    "categ_cols = ['workclass', 'education', 'marital_status', 'occupation',\n",
    "              'relationship', 'race', 'sex', 'native_country']\n",
    "\n",
    "# X_train\n",
    "categ_train = train_data_X[categ_cols]\n",
    "categ_train = pd.get_dummies(categ_train)\n",
    "\n",
    "# X_test\n",
    "categ_test = test_data_X[categ_cols]\n",
    "categ_test = pd.get_dummies(categ_test)\n",
    "\n",
    "# Replaces old categorical columns with encoded columns\n",
    "if categ_cols[0] in train_data_X.columns:\n",
    "    # X_train\n",
    "    train_data_X = train_data_X.drop(categ_cols, axis=1)\n",
    "    train_data_X = pd.concat((train_data_X, categ_train), axis=1)\n",
    "    \n",
    "    # X_test\n",
    "    test_data_X = test_data_X.drop(categ_cols, axis=1)\n",
    "    test_data_X = pd.concat((test_data_X, categ_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Splits Data into Training and Validation Sets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_X.iloc[:2800,:]\n",
    "y_train = train_data_y.iloc[:2800,:]\n",
    "X_val = train_data_X.iloc[2800:,:]\n",
    "y_val = train_data_y.iloc[2800:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Creates and fits logistic regression model\n",
    "mod = LogisticRegression(max_iter=1000)\n",
    "mod.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts output for validation set\n",
    "\n",
    "y_pred = mod.predict(X_val)\n",
    "y_val = np.array([i[0] for i in y_val.values.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Precision, Recall & Accuracy Functions</font>\n",
    "\n",
    "#### Manually calculates precision, recall & accuracy to display performance of logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y, y_preds):\n",
    "    \"\"\"\n",
    "    Return precision, which is TP/(TP+FP)\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in range(len(y_preds)):\n",
    "        if y_preds[i] == 1:\n",
    "            if y[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "                \n",
    "    return tp / (tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y, y_preds):\n",
    "    \"\"\"\n",
    "    Return recall, which is TP/(TP+FN)\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    for i in range(len(y_preds)):\n",
    "        if y_preds[i] == 1 and y[i] == 1:\n",
    "            tp += 1\n",
    "        elif y[i] == 1 and y_preds[i] == 0:\n",
    "            fn += 1\n",
    "                \n",
    "    return tp / (tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_preds):\n",
    "    \"\"\"\n",
    "    Return accuracy, which is (TP+TN)/(TP+FP+FN+TN)\n",
    "    \"\"\"\n",
    "    tp, tn, fp, fn = (0, 0, 0, 0)\n",
    "    \n",
    "    for i in range(len(y_preds)):\n",
    "        if y_preds[i] == 1 and y[i] == 1:\n",
    "            tp += 1\n",
    "        elif y_preds[i] == 1 and y[i] == 0:\n",
    "            fp += 1\n",
    "        elif y_preds[i] == 0 and y[i] == 1:\n",
    "            fn += 1\n",
    "        elif y_preds[i] == 0 and y[i] == 0:\n",
    "            tn += 1\n",
    "                \n",
    "    return (tp + tn) / (tp + fp + fn + tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Evaluates Performance of `y_pred` in `test_data`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the predictions to calculate accuracy, precision, recall\n",
    "\n",
    "print(f'Q1. Precision: {precision(y_val, y_pred):.5f}')\n",
    "print(f'Q2. Recall:    {recall(y_val, y_pred):.5f}')\n",
    "print(f'Q3. Accuracy:  {accuracy(y_val, y_pred):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "y_probs = mod.predict_proba(X_val)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_probs, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Tuning Hyperparameters of Logistic Regression Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_logistic_model(c, p, X_train, y_train, y_val):\n",
    "    \"\"\"Prints precision, recall & accuracy values,\n",
    "       based off logistic model's performance.\"\"\"\n",
    "    \n",
    "    # Builds model\n",
    "    mod = LogisticRegression(C=c, penalty=p, solver='liblinear').fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = mod.predict(X_val)\n",
    "\n",
    "    # Prints accuracy, precision & recall\n",
    "    print(f'Precision: {precision(y_val, y_pred):.5}')\n",
    "    print(f'Recall:    {recall(y_val, y_pred):.5}')\n",
    "    print(f'Accuracy:  {accuracy(y_val, y_pred):.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Builds a logistic regression model with hyperparameter **'C' set to 0.1** and **penalty set to 'l1'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_logistic_model(0.1, 'l1', X_train, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Builds a logistic regression model with hyperparameter **'C' set to 0.5** and **penalty set to 'l1'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_logistic_model(0.5, 'l1', X_train, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Builds a logistic regression model with hyperparameter **'C' set to 0.1** and **penalty set to 'l2'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_logistic_model(0.1, 'l2', X_train, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Builds a logistic regression model with hyperparameter **'C' set to 0.5** and **penalty set to 'l2'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_logistic_model(0.5, 'l2', X_train, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model out of the 4 listed above:\n",
    "\n",
    "**Model 2**, with hyperparameter 'C' set to 0.5 and penalty set to 'l1', is the best based off its high accuracy. Although model 4 has the same accuracy as model 2, model 2 has a higher precision than model 4. Furthermore, the recall values of the two models are very close. Therefore, **model 2 is the best based off the accuracy and precision**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Test Set Predictions</font>\n",
    "\n",
    "#### Makes predictions on `test_data` using a logistic regression model with the hyperparameters listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds one-hot encoded columns from training set that were not in test set\n",
    "for i in train_data_X.columns:\n",
    "    if i not in test_data.columns:\n",
    "        test_data_X[i] = 0\n",
    "\n",
    "# Sorts by columns\n",
    "train_data_X = train_data_X.sort_index(axis=1)\n",
    "test_data_X = test_data_X.sort_index(axis=1)\n",
    "\n",
    "# Logistic regression\n",
    "final_mod = LogisticRegression(C=0.5, penalty='l1', solver='liblinear').fit(train_data_X, train_data_y.values.ravel())\n",
    "\n",
    "# Predictions on test_data\n",
    "test_pred = final_mod.predict(test_data_X)\n",
    "test_val = np.array([i[0] for i in test_data_y.values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the predictions to calculate accuracy, precision, recall\n",
    "\n",
    "print(f'Q1. Precision: {precision(test_val, test_pred):.5f}')\n",
    "print(f'Q2. Recall:    {recall(test_val, test_pred):.5f}')\n",
    "print(f'Q3. Accuracy:  {accuracy(test_val, test_pred):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Results</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After training the logistic regression model with `train_data` and testing numerous hyperparameters, the prediction results for `train_data` were the following:\n",
    "\n",
    "**Precision:** 0.54599\n",
    "\n",
    "**Recall:**    0.63835\n",
    "\n",
    "**Accuracy:**  0.82203\n",
    "\n",
    "\n",
    "#### Evaluating the logistic regression model with `test_data` yielded the following prediction results:\n",
    "\n",
    "**Precision:** 0.60976\n",
    "\n",
    "**Recall:**    0.04149\n",
    "\n",
    "**Accuracy:**  0.80380\n",
    "\n",
    "\n",
    "\n",
    "#### The test set predictions resulted in a higher precision and slightly less accuracy as compared to the train data predictions. However, the precision value was significantly lower for the test set as compared to the training set. This means that the logistic model yields a relatively small amount of true positives as compared to false negatives for the test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
